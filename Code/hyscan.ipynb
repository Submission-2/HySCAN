{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7957692,"sourceType":"datasetVersion","datasetId":4680816},{"sourceId":7957702,"sourceType":"datasetVersion","datasetId":4680825},{"sourceId":10653461,"sourceType":"datasetVersion","datasetId":6597049},{"sourceId":12758465,"sourceType":"datasetVersion","datasetId":8065384}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import cv2\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport plotly.express as px\nsns.set_style('whitegrid')\nfrom sklearn.metrics import confusion_matrix , classification_report\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense , Flatten , Conv2D , MaxPooling2D , Dropout , Activation , BatchNormalization\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam , Adamax\nfrom tensorflow.keras import regularizers\n\n#Warnings\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\n#tf.keras.mixed_precision.set_global_policy('mixed_float16')\n\nimport tensorflow as tf\nimport numpy as np\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, BatchNormalization, ReLU, Add\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.losses import KLDivergence\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.applications import DenseNet121, ResNet50V2\nfrom tensorflow.keras.layers import GlobalAveragePooling2D\nimport copy\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, BatchNormalization, ReLU, Add\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.losses import KLDivergence\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.applications import DenseNet169, MobileNetV2, ResNet50, EfficientNetB0\nfrom tensorflow.keras.layers import GlobalAveragePooling2D\nimport copy\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nimport tensorflow as tf\nfrom tensorflow.keras import layers\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_s = np.load('X.npy')\ny_train_s = np.load('Y.npy')\n\nX_train_s.shape, y_train_s.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train_s, X_test_s, y_train_s, y_test_s = train_test_split(X_train_s, y_train_s, test_size=0.2, random_state=42)\nX_train_s, X_val_s, y_train_s, y_val_s = train_test_split(X_train_s, y_train_s, test_size=0.2, random_state=42)\n\nX_train_s.shape,X_test_s.shape, y_train_s.shape,y_test_s.shape, y_val_s.shape,y_val_s.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class GlobalAttentionNoiseLayer(layers.Layer):\n    def __init__(self, noise_factor=0.2, **kwargs):\n        super(GlobalAttentionNoiseLayer, self).__init__(**kwargs)\n        self.noise_factor = noise_factor\n\n    def build(self, input_shape):\n        self.alpha = self.add_weight(\n            shape=(1,),\n            initializer='ones',\n            trainable=True,\n            name='alpha'\n        )\n        super(GlobalAttentionNoiseLayer, self).build(input_shape)\n\n    def call(self, inputs, training=None):\n        if training:\n            noise = tf.random.normal(\n                shape=tf.shape(inputs),\n                mean=0.0,\n                stddev=self.noise_factor * self.alpha\n            )\n            return inputs + noise\n        else:\n            return inputs\n\n\nclass FeatureAttentionNoiseLayer(layers.Layer):\n    def __init__(self, noise_factor=0.2, learning_rate=0.001, **kwargs):\n        super(FeatureAttentionNoiseLayer, self).__init__(**kwargs)\n        self.noise_factor = noise_factor\n        self.learning_rate = learning_rate\n\n    def build(self, input_shape):\n        _, H, W, C = input_shape\n        self.alpha = self.add_weight(\n            shape=(H, W, C),\n            initializer='ones',\n            trainable=True,\n            name='alpha'\n        )\n        self.dense = layers.Dense(units=C, activation='relu')\n        super(FeatureAttentionNoiseLayer, self).build(input_shape)\n\n    def call(self, inputs, training=None):\n        if training:\n            noise = tf.random.normal(shape=tf.shape(inputs),\n                                     mean=0.0,\n                                     stddev=self.noise_factor)\n\n            global_avg_pooled = tf.reduce_mean(inputs, axis=[1, 2], keepdims=True)\n            delta_related = self.dense(global_avg_pooled)\n\n            attention_noise = inputs + delta_related * inputs * self.alpha * noise\n            # Optional regularization\n            \n            #self.add_loss(tf.reduce_mean(attention_noise))\n            \n            return attention_noise\n        else:\n            return inputs\n\n    def get_config(self):\n        config = super(FeatureAttentionNoiseLayer, self).get_config()\n        config.update({\n            'noise_factor': self.noise_factor,\n            'learning_rate': self.learning_rate\n        })\n        return config\n\n\n\n################################################ NORAN ################################################\n\nclass CombinedNoiseLayer(layers.Layer):\n    def __init__(self, global_noise_factor=0.2, feature_noise_factor=0.2,\n                 learning_rate=0.001, **kwargs):\n        super(CombinedNoiseLayer, self).__init__(**kwargs)\n        self.global_noise_layer = GlobalAttentionNoiseLayer(\n            noise_factor=global_noise_factor\n        )\n        self.feature_noise_layer = FeatureAttentionNoiseLayer(\n            noise_factor=feature_noise_factor,\n            learning_rate=learning_rate\n        )\n\n    def call(self, inputs, training=None):\n        if training:\n            x = self.global_noise_layer(inputs, training=training)\n            x = self.feature_noise_layer(x, training=training)\n            return x\n        else:\n            return inputs\n\n    def get_config(self):\n        config = super(CombinedNoiseLayer, self).get_config()\n        config.update({\n            'global_noise_factor': self.global_noise_layer.noise_factor,\n            'feature_noise_factor': self.feature_noise_layer.noise_factor,\n            'learning_rate': self.feature_noise_layer.learning_rate\n        })\n        return config\n\n\n# --- Spatial & Channel attention from your previous code --- #\nfrom tensorflow.keras.layers import Layer, Conv2D, GlobalAveragePooling2D, Dense\n\nclass TrainableSpatialAttentionLayer(Layer):\n    def __init__(self, **kwargs):\n        super(TrainableSpatialAttentionLayer, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        self.convolution = Conv2D(\n            filters=1,\n            kernel_size=(1, 1),\n            activation='sigmoid',\n            padding='same',\n            trainable=False\n        )\n        super(TrainableSpatialAttentionLayer, self).build(input_shape)\n\n    def call(self, inputs):\n        attention_weights = self.convolution(inputs)\n        return tf.multiply(inputs, attention_weights)\n\n\nclass TrainableChannelAttentionLayer(Layer):\n    def __init__(self, **kwargs):\n        super(TrainableChannelAttentionLayer, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        self.global_avg_pooling = GlobalAveragePooling2D()\n        self.dense1 = Dense(units=input_shape[-1] // 8,\n                            activation='relu',\n                            trainable=False)\n        self.dense2 = Dense(units=input_shape[-1],\n                            activation='sigmoid',\n                            trainable=False)\n        super(TrainableChannelAttentionLayer, self).build(input_shape)\n\n    def call(self, inputs):\n        avg_pool = self.global_avg_pooling(inputs)\n        dense1_out = self.dense1(avg_pool)\n        channel_attention_weights = self.dense2(dense1_out)\n        channel_attention_weights = tf.expand_dims(\n            tf.expand_dims(channel_attention_weights, 1), 1\n        )\n        return tf.multiply(inputs, channel_attention_weights)\n\n\n###########################  RecRAN ##############################\n\nclass TrainableCombinedAttentionLayer(Layer):\n    def __init__(self, spatial_noise_factor=0.6,\n                 channel_noise_factor=0.6, num_layers=3, **kwargs):\n        super(TrainableCombinedAttentionLayer, self).__init__(**kwargs)\n        self.spatial_attentions = [\n            TrainableSpatialAttentionLayer() for _ in range(num_layers)\n        ]\n        self.channel_attentions = [\n            TrainableChannelAttentionLayer() for _ in range(num_layers)\n        ]\n\n        # Trainable weights for noise factors\n        self.spatial_noise_weight = self.add_weight(\n            shape=(1,),\n            initializer='ones',\n            trainable=False,\n            name='spatial_noise_weight'\n        )\n        self.channel_noise_weight = self.add_weight(\n            shape=(1,),\n            initializer='ones',\n            trainable=False,\n            name='channel_noise_weight'\n        )\n\n        self.spatial_noise_factor = spatial_noise_factor\n        self.channel_noise_factor = channel_noise_factor\n\n    def call(self, inputs):\n        spatial_attention_output = inputs\n        channel_attention_output = inputs\n\n        for spatial_attention, channel_attention in zip(\n            self.spatial_attentions, self.channel_attentions\n        ):\n            spatial_attention_output = spatial_attention(spatial_attention_output)\n            channel_attention_output = channel_attention(channel_attention_output)\n\n        # Spatial & channel noise\n        spatial_noise = tf.random.normal(\n            shape=tf.shape(spatial_attention_output),\n            mean=0,\n            stddev=self.spatial_noise_factor\n        )\n        channel_noise = tf.random.normal(\n            shape=tf.shape(channel_attention_output),\n            mean=0,\n            stddev=self.channel_noise_factor\n        )\n\n        spatial_noise *= self.spatial_noise_weight + (\n            spatial_noise * self.spatial_noise_weight\n        )\n        channel_noise *= self.channel_noise_weight + (\n            channel_noise * self.channel_noise_weight\n        )\n\n        spatial_attention_output += spatial_noise\n        channel_attention_output += channel_noise\n\n        spatial_attention_output = tf.clip_by_value(\n            spatial_attention_output, 0.0, 1.0\n        )\n        channel_attention_output = tf.clip_by_value(\n            channel_attention_output, 0.0, 1.0\n        )\n\n        combined_attention1 = tf.multiply(\n            spatial_attention_output, channel_attention_output\n        )\n        combined_attention2 = tf.multiply(\n            spatial_attention_output, channel_attention_output\n        )\n        combined_attention3 = tf.multiply(\n            spatial_attention_output, channel_attention_output\n        )\n        combined_attention4 = tf.multiply(combined_attention1, combined_attention2)\n        combined_attention = tf.multiply(combined_attention3, combined_attention4)\n\n        return tf.multiply(inputs, combined_attention)\n\n\n# ----------------------------------------------------------------------\n# 3. SANI\n# ----------------------------------------------------------------------\n\nclass SoftplusMergedAttentionNoiseLayer(layers.Layer):\n    \"\"\"\n    Fuse two attention/noise mechanisms with softplus weights:\n\n      - path 1: CombinedNoiseLayer (global + feature noise)\n      - path 2: TrainableCombinedAttentionLayer (spatial + channel attention + noise)\n\n    x_gf  = CombinedNoiseLayer(x, training=...)\n    x_att = TrainableCombinedAttentionLayer(x)\n\n    Δ_gf  = x_gf  - x\n    Δ_att = x_att - x\n\n    w_g = softplus(theta_g) >= 0\n    w_a = softplus(theta_a) >= 0\n\n    Δ = (w_g * Δ_gf + w_a * Δ_att) / (w_g + w_a + eps)\n    y = x + Δ\n    \"\"\"\n\n    def __init__(self,\n                 global_noise_factor=0.2,\n                 feature_noise_factor=0.2,\n                 learning_rate=0.001,\n                 spatial_noise_factor=0.6,\n                 channel_noise_factor=0.6,\n                 num_layers=3,\n                 use_eval_noise=True,\n                 eps=1e-6,\n                 **kwargs):\n        super(SoftplusMergedAttentionNoiseLayer, self).__init__(**kwargs)\n\n        self.combined_noise = CombinedNoiseLayer(\n            global_noise_factor=global_noise_factor,\n            feature_noise_factor=feature_noise_factor,\n            learning_rate=learning_rate\n        )\n\n        self.attention_noise = TrainableCombinedAttentionLayer(\n            spatial_noise_factor=spatial_noise_factor,\n            channel_noise_factor=channel_noise_factor,\n            num_layers=num_layers\n        )\n\n        self.use_eval_noise = bool(use_eval_noise)\n        self.eps = float(eps)\n\n    def build(self, input_shape):\n        self.theta_global_feat = self.add_weight(\n            name=self.name + \"_theta_global_feat\",\n            shape=(),\n            initializer=tf.keras.initializers.Zeros(),\n            trainable=True\n        )\n        self.theta_att = self.add_weight(\n            name=self.name + \"_theta_att\",\n            shape=(),\n            initializer=tf.keras.initializers.Zeros(),\n            trainable=True\n        )\n        super().build(input_shape)\n\n    def call(self, inputs, training=None):\n        #if training is None:\n         #   training = tf.keras.backend.learning_phase()\n\n        x = inputs\n\n        # Path 1: global + feature noise\n        if training:\n            x_gf = self.combined_noise(x, training=True)\n        else:\n            if self.use_eval_noise:\n                x_gf = self.combined_noise(x, training=True)   # force noise at inference\n            else:\n                x_gf = self.combined_noise(x, training=False)\n\n        # Path 2: spatial + channel attention noise\n        x_att = self.attention_noise(x)  # no 'training' flag in your code\n\n        # Noise increments\n        delta_gf = x_gf - x\n        delta_att = x_att - x\n\n        w_g = tf.nn.softplus(self.theta_global_feat)  # >=0\n        w_a = tf.nn.softplus(self.theta_att)          # >=0\n\n        denom = w_g + w_a + self.eps\n        delta = (w_g * delta_gf + w_a * delta_att) / denom\n\n        y = x + delta\n        return y\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Layer, Conv2D, GlobalAveragePooling2D, Dense\n\n# ----------------------------------------------------------------------\n# 0. Setup\n# ----------------------------------------------------------------------\ntf.keras.backend.clear_session()\ntf.random.set_seed(0)\nnp.random.seed(0)\n\n# ----------------------------------------------------------------------\n# 1. Your attention code, but with trainable=False everywhere\n# ----------------------------------------------------------------------\n\n\n###########  Spatial\\Local Attention ############\nclass TrainableSpatialAttentionLayer(Layer):\n    \"\"\"\n    Your spatial attention, but convolution is NON-TRAINABLE.\n    \"\"\"\n    def __init__(self, **kwargs):\n        super(TrainableSpatialAttentionLayer, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        self.convolution = Conv2D(\n            filters=1,\n            kernel_size=(1, 1),\n            activation='sigmoid',\n            padding='same',\n            trainable=False,                    # CHANGED\n            name=self.name + \"_conv\"\n        )\n        super(TrainableSpatialAttentionLayer, self).build(input_shape)\n\n    def call(self, inputs):\n        attention_weights = self.convolution(inputs)\n        return tf.multiply(inputs, attention_weights)\n\n\n############# Channel Attention ###############\n\nclass TrainableChannelAttentionLayer(Layer):\n    \"\"\"\n    Your channel attention, but Dense layers are NON-TRAINABLE.\n    \"\"\"\n    def __init__(self, **kwargs):\n        super(TrainableChannelAttentionLayer, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        self.global_avg_pooling = GlobalAveragePooling2D(name=self.name + \"_gap\")\n        self.dense1 = Dense(\n            units=input_shape[-1] // 8,\n            activation='relu',\n            trainable=False,                   # CHANGED\n            name=self.name + \"_dense1\"\n        )\n        self.dense2 = Dense(\n            units=input_shape[-1],\n            activation='sigmoid',\n            trainable=False,                   # CHANGED\n            name=self.name + \"_dense2\"\n        )\n        super(TrainableChannelAttentionLayer, self).build(input_shape)\n\n    def call(self, inputs):\n        avg_pool = self.global_avg_pooling(inputs)\n        dense1_out = self.dense1(avg_pool)\n        channel_attention_weights = self.dense2(dense1_out)\n        channel_attention_weights = tf.expand_dims(\n            tf.expand_dims(channel_attention_weights, 1), 1\n        )\n        return tf.multiply(inputs, channel_attention_weights)\n\n\n###########################  RecRAN ##############################\n\nclass TrainableCombinedAttentionLayer(Layer):\n    \"\"\"\n    Exactly your TrainableCombinedAttentionLayer logic, except:\n      - All internal layers are frozen (trainable=False).\n      - spatial_noise_weight and channel_noise_weight are NON-TRAINABLE.\n    \"\"\"\n    def __init__(self, spatial_noise_factor=0.6,\n                 channel_noise_factor=0.6,\n                 num_layers=3, **kwargs):\n        super(TrainableCombinedAttentionLayer, self).__init__(**kwargs)\n        self.spatial_attentions = [\n            TrainableSpatialAttentionLayer(name=f\"{self.name}_spat{i}\")\n            for i in range(num_layers)\n        ]\n        self.channel_attentions = [\n            TrainableChannelAttentionLayer(name=f\"{self.name}_chan{i}\")\n            for i in range(num_layers)\n        ]\n\n        # Noise factor weights – now NON-TRAINABLE\n        self.spatial_noise_weight = self.add_weight(\n            shape=(1,),\n            initializer='ones',\n            trainable=False,                  # CHANGED\n            name=self.name + \"_spatial_noise_weight\"\n        )\n        self.channel_noise_weight = self.add_weight(\n            shape=(1,),\n            initializer='ones',\n            trainable=False,                  # CHANGED\n            name=self.name + \"_channel_noise_weight\"\n        )\n\n        self.spatial_noise_factor = float(spatial_noise_factor)\n        self.channel_noise_factor = float(channel_noise_factor)\n\n    def call(self, inputs):\n        spatial_attention_output = inputs\n        channel_attention_output = inputs\n\n        for spatial_attention, channel_attention in zip(\n            self.spatial_attentions, self.channel_attentions\n        ):\n            # Spatial Attention\n            spatial_attention_output = spatial_attention(spatial_attention_output)\n\n            # Channel Attention\n            channel_attention_output = channel_attention(channel_attention_output)\n\n        # Generate spatial and channel noise\n        spatial_noise = tf.random.normal(\n            shape=tf.shape(spatial_attention_output),\n            mean=0.0,\n            stddev=self.spatial_noise_factor\n        )\n        channel_noise = tf.random.normal(\n            shape=tf.shape(channel_attention_output),\n            mean=0.0,\n            stddev=self.channel_noise_factor\n        )\n\n        # Scale the noise with (frozen) weights\n        spatial_noise *= self.spatial_noise_weight + (\n            spatial_noise * self.spatial_noise_weight\n        )\n        channel_noise *= self.channel_noise_weight + (\n            channel_noise * self.channel_noise_weight\n        )\n\n        # Add spatial attention noise\n        spatial_attention_output += spatial_noise\n\n        # Add channel attention noise\n        channel_attention_output += channel_noise\n\n        # Clip attention maps to ensure they are within the valid range [0, 1]\n        spatial_attention_output = tf.clip_by_value(spatial_attention_output, 0.0, 1.0)\n        channel_attention_output = tf.clip_by_value(channel_attention_output, 0.0, 1.0)\n\n        ########################### Combine attention mechanisms with recursuve nature #########################\n        \n        combined_attention1 = tf.multiply(spatial_attention_output, channel_attention_output)\n        combined_attention2 = tf.multiply(spatial_attention_output, channel_attention_output)\n        combined_attention3 = tf.multiply(spatial_attention_output, channel_attention_output)\n        combined_attention4 = tf.multiply(combined_attention1, combined_attention2)\n        combined_attention = tf.multiply(combined_attention3, combined_attention4)\n\n        return tf.multiply(inputs, combined_attention)\n\n\n# ----------------------------------------------------------------------\n# 2. Conv layer with weight noise gated by your (frozen) attention-noise\n# ----------------------------------------------------------------------\n\n\"\"\"\nConv2D whose weights are randomized using your Frozen CombinedAttentionLayer.\n\nFor each forward pass:\n\n    1. att_out = CombinedAttention(x)      # your code, frozen\n    2. gate_in = mean(att_out, over N,H,W) # per-input-channel gate\n    3. normalize gate_in to [0,1]\n    4. eps ~ N(0, noise_std^2) same shape as W\n    5. noise_gated = eps * gate_in_reshaped\n    6. W_eff = W_base + rho * noise_gated\n    7. y = Conv2D(x, W_eff) + BN + optional ReLU\n\n- Combined attention is NON-TRAINABLE (frozen defense structure).\n- rho (noise strength) is TRAINABLE and learned via backprop.\n\"\"\"\n\n'''class AttentionWeightNoiseConv2D(layers.Layer):\n    \n\n    def __init__(self,\n                 filters,\n                 kernel_size,\n                 strides=1,\n                 padding=\"same\",\n                 use_bias=False,\n                 activation=True,\n                 noise_std=0.05,\n                 spatial_noise_factor=0.6,\n                 channel_noise_factor=0.6,\n                 att_num_layers=3,\n                 use_eval_noise=True,\n                 **kwargs):\n        super().__init__(**kwargs)\n        if isinstance(kernel_size, int):\n            kernel_size = (kernel_size, kernel_size)\n\n        self.filters = int(filters)\n        self.kernel_size = kernel_size\n        self.strides = strides\n        self.padding = padding\n        self.use_bias = use_bias\n        self.activation = activation\n        self.noise_std = float(noise_std)\n        self.use_eval_noise = bool(use_eval_noise)\n\n        # Base conv + BN + optional ReLU\n        self.conv = Conv2D(\n            filters=self.filters,\n            kernel_size=self.kernel_size,\n            strides=self.strides,\n            padding=self.padding,\n            use_bias=self.use_bias,\n            kernel_initializer=\"he_normal\",\n            name=self.name + \"_conv\"\n        )\n        self.bn = layers.BatchNormalization(name=self.name + \"_bn\")\n        self.act = layers.ReLU(name=self.name + \"_relu\") if self.activation else None\n\n        # Your combined attention–noise, but frozen\n        self.att = TrainableCombinedAttentionLayer(\n            spatial_noise_factor=spatial_noise_factor,\n            channel_noise_factor=channel_noise_factor,\n            num_layers=att_num_layers,\n            name=self.name + \"_att\"\n        )\n\n    def build(self, input_shape):\n        # Build conv & BN\n        self.conv.build(input_shape)\n        conv_out_shape = self.conv.compute_output_shape(input_shape)\n        self.bn.build(conv_out_shape)\n\n        # Trainable noise strength (per conv layer)\n        self.rho_logit = self.add_weight(\n            name=self.name + \"_rho_logit\",\n            shape=(),\n            initializer=tf.keras.initializers.Constant(-2.0),  # small initial rho\n            trainable=True\n        )\n\n        super().build(input_shape)\n\n    def call(self, x, training=None):\n        W_base = self.conv.kernel          # [kh,kw,C_in,C_out]\n        strides_tf = [1, self.conv.strides[0], self.conv.strides[1], 1]\n        padding_tf = self.conv.padding.upper()  # \"SAME\" or \"VALID\"\n\n        # 1) Run your frozen combined attention on the features\n        att_out = self.att(x)              # [N,H,W,C_in]\n\n        # 2) Derive a per-input-channel gating vector from att_out\n        gate_in = tf.reduce_mean(att_out, axis=[0, 1, 2])   # [C_in]\n        # Normalize to [0,1] to keep noise scale stable\n        gate_in = gate_in / (tf.reduce_max(tf.abs(gate_in)) + 1e-6)\n        gate_in = tf.reshape(gate_in, [1, 1, -1, 1])        # [1,1,C_in,1]\n\n        # 3) Sample Gaussian noise in weight space\n        eps = tf.random.normal(\n            shape=tf.shape(W_base),\n            mean=0.0,\n            stddev=self.noise_std\n        )  # [kh,kw,C_in,C_out]\n\n        # Gate noise per input channel using your attention-derived gate\n        noise_gated = eps * gate_in\n\n        # 4) Trainable noise ratio\n        rho = tf.nn.softplus(self.rho_logit)  # >= 0\n\n        # 5) Decide if noise is active\n        #noise_on = bool(training) or self.use_eval_noise\n\n        #if noise_on:\n        \n        W_eff = W_base + rho * noise_gated\n        \n        #else:\n         #   #W_eff = W_base\n          #  W_eff = W_base + rho * noise_gated\n\n        # 6) Perform convolution with W_eff\n        y = tf.nn.conv2d(x, W_eff, strides=strides_tf, padding=padding_tf)\n        if self.conv.use_bias and self.conv.bias is not None:\n            y = tf.nn.bias_add(y, self.conv.bias)\n\n        # 7) BN + activation\n        y = self.bn(y, training=training)\n        if self.act is not None:\n            y = self.act(y)\n        return y'''\n\n\n\nclass AttentionWeightNoiseConv2D(layers.Layer):\n    \"\"\"\n    Conv2D whose weights are randomized using BOTH:\n\n      (1) Your TrainableCombinedAttentionLayer (spatial+channel attention+noise)\n      (2) Your CombinedNoiseLayer (global + feature attention noise)\n\n    Inside the conv, we build a Softplus-style fusion in *feature space*:\n\n        x_gf  = CombinedNoiseLayer(x, training=...)\n        x_att = TrainableCombinedAttentionLayer(x)\n\n        Δ_gf  = x_gf  - x\n        Δ_att = x_att - x\n\n        w_g = softplus(theta_g) >= 0\n        w_a = softplus(theta_a) >= 0\n\n        x_fused = x + (w_g * Δ_gf + w_a * Δ_att) / (w_g + w_a + eps)\n\n    Then we compress x_fused into a per-input-channel gate and use it to\n    modulate Gaussian weight noise:\n\n        gate_in = mean(x_fused, over N,H,W)   -> [C_in]\n        noise   = N(0, noise_std^2) in weight space\n        noise_gated = noise * gate_in (broadcasted to [kh,kw,C_in,C_out])\n\n        W_eff = W_base + rho * noise_gated\n\n    - SINGLE conv branch (no multi-branch, no multi-scale).\n    - Uses your attention noise *and* global/feature noise.\n    - Softplus mixing is trainable (theta_g, theta_a).\n    \"\"\"\n\n    def __init__(self,\n                 filters,\n                 kernel_size,\n                 strides=1,\n                 padding=\"same\",\n                 use_bias=False,\n                 activation=True,\n                 noise_std=0.05,\n                 spatial_noise_factor=0.6,\n                 channel_noise_factor=0.6,\n                 att_num_layers=3,\n                 use_eval_noise=True,\n                 **kwargs):\n        super().__init__(**kwargs)\n        if isinstance(kernel_size, int):\n            kernel_size = (kernel_size, kernel_size)\n\n        self.filters = int(filters)\n        self.kernel_size = kernel_size\n        self.strides = strides\n        self.padding = padding\n        self.use_bias = use_bias\n        self.activation = activation\n        self.noise_std = float(noise_std)\n        self.use_eval_noise = bool(use_eval_noise)\n\n        # Base conv + BN + optional ReLU\n        self.conv = Conv2D(\n            filters=self.filters,\n            kernel_size=self.kernel_size,\n            strides=self.strides,\n            padding=self.padding,\n            use_bias=self.use_bias,\n            kernel_initializer=\"he_normal\",\n            name=self.name + \"_conv\"\n        )\n        self.bn = layers.BatchNormalization(name=self.name + \"_bn\")\n        self.act = layers.ReLU(name=self.name + \"_relu\") if self.activation else None\n\n        # Your combined attention–noise (spatial + channel), typically frozen\n        self.att = TrainableCombinedAttentionLayer(\n            spatial_noise_factor=spatial_noise_factor,\n            channel_noise_factor=channel_noise_factor,\n            num_layers=att_num_layers,\n            name=self.name + \"_att\"\n        )\n\n        # NEW: global + feature attention noise (your CombinedNoiseLayer)\n        # used ONLY to help shape the weight noise.\n        self.combined_noise = CombinedNoiseLayer(\n            global_noise_factor=0.2,\n            feature_noise_factor=0.2,\n            learning_rate=0.001\n        )\n\n    def build(self, input_shape):\n        # Build underlying conv & BN\n        self.conv.build(input_shape)\n        conv_out_shape = self.conv.compute_output_shape(input_shape)\n        self.bn.build(conv_out_shape)\n\n        # Trainable noise strength (per conv layer)\n        self.rho_logit = self.add_weight(\n            name=self.name + \"_rho_logit\",\n            shape=(),\n            initializer=tf.keras.initializers.Constant(-2.0),  # small initial rho\n            trainable=True\n        )\n\n        # NEW: Softplus mixing weights for the two noise paths\n        self.theta_global_feat = self.add_weight(\n            name=self.name + \"_theta_global_feat\",\n            shape=(),\n            initializer=tf.keras.initializers.Zeros(),\n            trainable=True\n        )\n        self.theta_att_feat = self.add_weight(\n            name=self.name + \"_theta_att_feat\",\n            shape=(),\n            initializer=tf.keras.initializers.Zeros(),\n            trainable=True\n        )\n\n        super().build(input_shape)\n\n    def call(self, x, training=None):\n        W_base = self.conv.kernel          # [kh, kw, C_in, C_out]\n        strides_tf = [1,\n                      self.conv.strides[0],\n                      self.conv.strides[1],\n                      1]\n        padding_tf = self.conv.padding.upper()  # \"SAME\" or \"VALID\"\n\n        # ------------------------------------------------------------------\n        # 1) Feature-space fusion of your two attention/noise mechanisms\n        # ------------------------------------------------------------------\n        # Path 1: global + feature noise\n        if training or self.use_eval_noise:\n            x_gf = self.combined_noise(x, training=True)\n        else:\n            x_gf = self.combined_noise(x, training=False)\n\n        # Path 2: spatial + channel attention noise\n        x_att = self.att(x)  # your TrainableCombinedAttentionLayer\n\n        # Increments\n        delta_gf = x_gf - x\n        delta_att = x_att - x\n\n        # Softplus mixing weights (>= 0)\n        w_g = tf.nn.softplus(self.theta_global_feat)\n        w_a = tf.nn.softplus(self.theta_att_feat)\n\n        denom = w_g + w_a + 1e-6\n        #x_fused = x + (w_g * delta_gf + w_a * delta_att) / denom\n        x_fused = (w_g * delta_gf + w_a * delta_att) / denom\n\n        # ------------------------------------------------------------------\n        # 2) Turn fused features into a per-input-channel gate\n        # ------------------------------------------------------------------\n        # gate_in: [C_in]\n        gate_in = tf.reduce_mean(x_fused, axis=[0, 1, 2])\n        gate_in = gate_in / (tf.reduce_max(tf.abs(gate_in)) + 1e-6)\n        gate_in = tf.reshape(gate_in, [1, 1, -1, 1])   # [1,1,C_in,1]\n\n        # ------------------------------------------------------------------\n        # 3) Sample Gaussian noise in weight space and gate it\n        # ------------------------------------------------------------------\n        eps = tf.random.normal(\n            shape=tf.shape(W_base),\n            mean=0.0,\n            stddev=self.noise_std\n        )  # [kh, kw, C_in, C_out]\n\n        # Per-input-channel gating of weight noise\n        noise_gated = eps * gate_in  # broadcasts to [kh,kw,C_in,C_out]\n\n        # Trainable scale of weight noise\n        rho = tf.nn.softplus(self.rho_logit)  # >= 0\n\n        # Effective weights\n        W_eff = W_base + rho * noise_gated\n\n        # ------------------------------------------------------------------\n        # 4) Convolution with W_eff + BN + optional activation\n        # ------------------------------------------------------------------\n        y = tf.nn.conv2d(x, W_eff, strides=strides_tf, padding=padding_tf)\n        if self.conv.use_bias and self.conv.bias is not None:\n            y = tf.nn.bias_add(y, self.conv.bias)\n\n        y = self.bn(y, training=training)\n        if self.act is not None:\n            y = self.act(y)\n        return y\n\n\n\n# ----------------------------------------------------------------------\n# 3. ResNet-18 style block using AttentionWeightNoiseConv2D\n# ----------------------------------------------------------------------\n\n############################# HySCAN which replaces standard convolution block   ##################################\n\nclass ResidualBlockWithWeightNoise(layers.Layer):\n    \"\"\"\n    Basic ResNet-18 block:\n\n        x -> Conv(noisy weights, stride)\n           -> Conv(noisy weights, stride=1)\n           -> + shortcut\n           -> ReLU\n    \"\"\"\n    def __init__(self, filters, stride=1, noise_std=0.05,\n                 spatial_noise_factor=0.6, channel_noise_factor=0.6,\n                 att_num_layers=3, **kwargs):\n        super().__init__(**kwargs)\n        self.filters = int(filters)\n        self.stride = int(stride)\n        self.noise_std = float(noise_std)\n        self.spatial_noise_factor = float(spatial_noise_factor)\n        self.channel_noise_factor = float(channel_noise_factor)\n        self.att_num_layers = int(att_num_layers)\n\n        ################################# RWAN as implicit stochasticity which replaces standard convolution layer   ###############################################\n        \n        self.conv1 = AttentionWeightNoiseConv2D(\n            filters=self.filters,\n            kernel_size=3,\n            strides=self.stride,\n            padding=\"same\",\n            use_bias=False,\n            activation=True,\n            noise_std=self.noise_std,\n            spatial_noise_factor=self.spatial_noise_factor,\n            channel_noise_factor=self.channel_noise_factor,\n            att_num_layers=self.att_num_layers,\n            use_eval_noise=True,\n            name=self.name + \"_conv1\"\n        )\n\n        ################################# RWAN as implicit stochasticity which replaces standard convolution layer   ###############################################\n        \n        self.conv2 = AttentionWeightNoiseConv2D(\n            filters=self.filters,\n            kernel_size=3,\n            strides=1,\n            padding=\"same\",\n            use_bias=False,\n            activation=False,\n            noise_std=self.noise_std,\n            spatial_noise_factor=self.spatial_noise_factor,\n            channel_noise_factor=self.channel_noise_factor,\n            att_num_layers=self.att_num_layers,\n            use_eval_noise=True,\n            name=self.name + \"_conv2\"\n        )\n\n        self.proj = None\n        self.proj_bn = None\n\n        ###################################### SANI as explicit stochasticity at the end of HySCAN block  ##########################################################\n        \n        self.attention = SoftplusMergedAttentionNoiseLayer(\n        global_noise_factor=0.2,\n        feature_noise_factor=0.2,\n        spatial_noise_factor=0.6,\n        channel_noise_factor=0.6,\n        num_layers=3,\n        use_eval_noise=True,\n        #name=\"stage1_softplus_noise\"\n    )\n\n    def build(self, input_shape):\n        in_ch = int(input_shape[-1])\n        if in_ch != self.filters or self.stride != 1:\n            self.proj = Conv2D(\n                filters=self.filters,\n                kernel_size=1,\n                strides=self.stride,\n                padding=\"same\",\n                use_bias=False,\n                kernel_initializer=\"he_normal\",\n                name=self.name + \"_proj_conv\"\n            )\n            self.proj_bn = layers.BatchNormalization(name=self.name + \"_proj_bn\")\n        super().build(input_shape)\n\n    def call(self, x, training=None):\n\n        ################################# RWAN as implicit stochasticity which replaces standard convolution layer   ###############################################\n        y = self.conv1(x, training=training)\n        #y = self.attention(y)\n\n        ################################# RWAN as implicit stochasticity which replaces standard convolution layer   ###############################################\n        y = self.conv2(y, training=training)\n        \n\n        if self.proj is not None:\n            shortcut = self.proj_bn(self.proj(x), training=training)\n        else:\n            shortcut = x\n\n        out = tf.nn.relu(y + shortcut)\n\n        ###################################### SANI as explicit stochasticity at the end of HySCAN block  ##########################################################\n        out = self.attention(out)\n        return out\n\n\n\n\n\ndef _make_stage(x, filters, num_blocks, stride, noise_std,\n                spatial_noise_factor, channel_noise_factor,\n                att_num_layers, name_prefix):\n\n\n    ############################# HySCAN which replaces standard convolution block   ##################################\n    \n    x = ResidualBlockWithWeightNoise(\n        filters=filters,\n        stride=stride,\n        noise_std=noise_std,\n        spatial_noise_factor=spatial_noise_factor,\n        channel_noise_factor=channel_noise_factor,\n        att_num_layers=att_num_layers,\n        name=name_prefix + \"_block0\"\n    )(x)\n\n    '''x = SoftplusMergedAttentionNoiseLayer(\n        global_noise_factor=0.2,\n        feature_noise_factor=0.2,\n        spatial_noise_factor=0.3,\n        channel_noise_factor=0.3,\n        num_layers=3,\n        use_eval_noise=True,\n        #name=\"stage1_softplus_noise\"\n    )(x)'''\n\n    ############################# HySCAN which replaces standard convolution block   ##################################\n    \n    for i in range(1, num_blocks):\n        x = ResidualBlockWithWeightNoise(\n            filters=filters,\n            stride=1,\n            noise_std=noise_std,\n            spatial_noise_factor=spatial_noise_factor,\n            channel_noise_factor=channel_noise_factor,\n            att_num_layers=att_num_layers,\n            name=f\"{name_prefix}_block{i}\"\n        )(x)\n\n    ###################################### SANI as explicit stochasticity at the end of HySCAN block  ##########################################################\n    \n    x = SoftplusMergedAttentionNoiseLayer(\n    global_noise_factor=0.2,\n    feature_noise_factor=0.2,\n    spatial_noise_factor=0.6,\n    channel_noise_factor=0.6,\n    num_layers=3,\n    use_eval_noise=True,\n    #name=\"stage1_softplus_noise\"\n)(x)\n    return x\n\n\n# ----------------------------------------------------------------------\n# 4. Full ResNet-18 backbone with attention-noisy weights\n# ----------------------------------------------------------------------\n\ndef build_resnet18_attention_noisy_weights(input_shape=(128, 128, 3),\n                                           num_classes=5,\n                                           base_width=64,\n                                           noise_std=0.05,\n                                           spatial_noise_factor=0.6,\n                                           channel_noise_factor=0.6,\n                                           att_num_layers=3):\n    \"\"\"\n    ResNet-18 topology [2,2,2,2] where every conv in every block is:\n        AttentionWeightNoiseConv2D\n    which uses your frozen TrainableCombinedAttentionLayer to shape\n    weight noise.\n\n    No spectral norm, no GroupSort.\n    \"\"\"\n    inputs = tf.keras.Input(shape=input_shape)\n\n    # Stem\n    x = Conv2D(\n        filters=base_width,\n        kernel_size=3,\n        strides=1,\n        padding=\"same\",\n        use_bias=False,\n        kernel_initializer=\"he_normal\",\n        name=\"stem_conv\"\n    )(inputs)\n    x = layers.BatchNormalization(name=\"stem_bn\")(x)\n    x = layers.ReLU(name=\"stem_relu\")(x)\n\n    # ResNet-18 stages\n    x = _make_stage(x, base_width,     num_blocks=2, stride=1,\n                    noise_std=noise_std,\n                    spatial_noise_factor=spatial_noise_factor,\n                    channel_noise_factor=channel_noise_factor,\n                    att_num_layers=att_num_layers,\n                    name_prefix=\"stage1\")\n\n    x = _make_stage(x, base_width * 2, num_blocks=2, stride=2,\n                    noise_std=noise_std,\n                    spatial_noise_factor=spatial_noise_factor,\n                    channel_noise_factor=channel_noise_factor,\n                    att_num_layers=att_num_layers,\n                    name_prefix=\"stage2\")\n\n    x = _make_stage(x, base_width * 4, num_blocks=2, stride=2,\n                    noise_std=noise_std,\n                    spatial_noise_factor=spatial_noise_factor,\n                    channel_noise_factor=channel_noise_factor,\n                    att_num_layers=att_num_layers,\n                    name_prefix=\"stage3\")\n\n    x = _make_stage(x, base_width * 8, num_blocks=2, stride=2,\n                    noise_std=noise_std,\n                    spatial_noise_factor=spatial_noise_factor,\n                    channel_noise_factor=channel_noise_factor,\n                    att_num_layers=att_num_layers,\n                    name_prefix=\"stage4\")\n\n    # Head\n    x = layers.GlobalAveragePooling2D(name=\"avgpool\")(x)\n    outputs = layers.Dense(\n        num_classes,\n        activation=\"softmax\",   # if you want logits, use activation=None and from_logits=True\n        name=\"head_dense\"\n    )(x)\n\n    model = tf.keras.Model(inputs, outputs, name=\"ResNet18_AttentionNoisyWeights\")\n    return model\n\n\n# ----------------------------------------------------------------------\n# 5. Example: build & compile\n# ----------------------------------------------------------------------\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\n\n# ------------------------------------------------------------------\n# 1️⃣  Hyper-parameters\n# ------------------------------------------------------------------\nsigma_train  = 0.5          # same σ you will use later for certification\nbatch_size   = 8\nepochs       = 100\n\n\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\n\ninitial_gamma = 0.5\nlearning_rate = 1e-2\noptimizer = Adam(learning_rate=0.001)\n#opt = Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.9, epsilon=None, amsgrad=False)\n# Compile the model with the custom optimizer\nmodel.compile(optimizer=optimizer,\n              loss='categorical_crossentropy',\n              #loss_weights=[initial_gamma, (1 -  initial_gamma)],\n              metrics=['accuracy'], jit_compile=True)\n\n\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\ndef checkpoint_callback():\n\n    checkpoint_filepath = 'best1_model_cer_skin_lung.keras'\n\n    model_checkpoint_callback= ModelCheckpoint(filepath=checkpoint_filepath,\n                           save_weights_only=False,\n                           #frequency='epoch',\n                           monitor='val_loss',\n                           save_best_only=True,\n                            mode='min',\n                           verbose=1)\n\n    return model_checkpoint_callback\n\ndef early_stopping(patience):\n    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', restore_best_weights=True, patience=60, verbose=1)\n    return es_callback\n\n\n\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n                              patience=50, verbose = 1, min_lr=0.00001)\n\ncheckpoint_callback = checkpoint_callback()\n\nearly_stopping = early_stopping(patience=100)\ncallbacks = [checkpoint_callback, early_stopping, reduce_lr]\n            \n\n\n# ------------------------------------------------------------------\n# 2️⃣  Build tf.data pipelines\n# ------------------------------------------------------------------\ngauss = tf.keras.layers.GaussianNoise(stddev=sigma_train)\n\ndef add_noise(x, y):\n    \"\"\"\n    Add i.i.d. Gaussian noise **only during training**.\n    Keras will pass 'training=True' when this dataset\n    is used for .fit; no noise when you later call model(x, training=False).\n    \"\"\"\n    x = gauss(x, training=True)        # <- noise goes here\n    return x, y\n\ngauss = tf.keras.layers.GaussianNoise(stddev=sigma_train)\n\ndef add_noise(x, y):\n    x = tf.cast(x, tf.float32) / 255.0       # ①  uint8 → float32  [0,1]\n    x = gauss(x, training=True)              # ②  additive N(0,σ²)\n    return x, y\n\ndef preprocess_val(x, y):\n    x = tf.cast(x, tf.float32) / 255.0       # same cast, but NO noise\n    return x, y\n\n\ntrain_ds = (\n    tf.data.Dataset.from_tensor_slices((X_train_s, y_train_s))\n      .shuffle(len(X_train_s))\n      .batch(batch_size)\n      .map(add_noise,  num_parallel_calls=tf.data.AUTOTUNE)\n      .prefetch(tf.data.AUTOTUNE)\n)\n\nval_ds = (\n    tf.data.Dataset.from_tensor_slices((X_val_s, y_val_s))\n      .batch(batch_size)\n      .prefetch(tf.data.AUTOTUNE)      # **no** noise on validation set\n)\n\n# ------------------------------------------------------------------\n# 3️⃣  Fit exactly as before\n# ------------------------------------------------------------------\nhistory = model.fit(\n    train_ds,\n    epochs         = epochs,\n    validation_data= val_ds,\n    verbose        = 1,\n    callbacks      = callbacks,        # your ModelCheckpoint / EarlyStopping\n    shuffle        = False             # shuffled already in the pipeline\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# hybrid_certifier.py\nimport tensorflow as tf, numpy as np\nfrom scipy.stats import beta, norm\n\n# ---------- One-sided lower Clopper–Pearson bound ----------\ndef lower_confidence_bound(k, n, alpha):\n    # P(Bin(n, p) >= k) >= alpha  ⇒ lower bound on p\n    return beta.ppf(alpha, k, n - k + 1) if k > 0 else 0.0\n\n# ---------- Randomized smoothing ----------\nclass SmoothedClassifier:\n    def __init__(self, base_model, sigma):\n        \"\"\"\n        base_model must be DETERMINISTIC when called with training=False.\n        sigma: std-dev of the Gaussian used BOTH for training & certification.\n        \"\"\"\n        self.f = base_model\n        self.sigma = float(sigma)\n        self.num_classes = int(base_model.output_shape[-1])\n\n    @tf.function(jit_compile=True)\n    def _predict_noisy(self, x_batch):\n        noise = tf.random.normal(tf.shape(x_batch)) * self.sigma\n        logits = self.f(x_batch + noise, training=False)\n        return tf.argmax(logits, axis=-1)\n\n    def sample_class(self, x, N0=1000, batch=128):\n        counts = np.zeros(self.num_classes, dtype=np.int32)\n        reps = tf.repeat(x[None, ...], batch, axis=0)\n        for done in range(0, N0, batch):\n            m = min(batch, N0 - done)\n            preds = self._predict_noisy(reps[:m])\n            counts += np.bincount(preds.numpy(), minlength=self.num_classes)\n        return int(np.argmax(counts))\n\n    def certify(self, x, N=100_000, N0=1000, alpha=1e-3, batch=512):\n        A = self.sample_class(x, N0=N0, batch=batch)\n        countA = 0\n        reps = tf.repeat(x[None, ...], batch, axis=0)\n        for done in range(0, N, batch):\n            m = min(batch, N - done)\n            preds = self._predict_noisy(reps[:m])\n            countA += int(np.sum(preds.numpy() == A))\n        pA_low = lower_confidence_bound(countA, N, alpha)\n        if pA_low <= 0.5:\n            return 0.0\n        return self.sigma * norm.ppf(pA_low)\n\n# ---------- Deterministic (Lipschitz) branch ----------\ndef deterministic_radius(model, x, L=1.0):\n    \"\"\"\n    r_det = margin / (2L), where margin = top1 - top2 logit.\n    Only valid if your network has a PROVABLE Lipschitz constant ≤ L.\n    \"\"\"\n    logits = model(x[None, ...], training=False)  # deterministic forward\n    top2 = tf.nn.top_k(logits, k=2).values\n    margin = float((top2[:, 0] - top2[:, 1])[0].numpy())\n    return max(margin / (2.0 * float(L)), 0.0)\n\n# ---------- Hybrid wrapper ----------\nclass HybridCertifier:\n    def __init__(self, base_model, sigma, L=1.0):\n        self.smooth = SmoothedClassifier(base_model, sigma)\n        self.model  = base_model\n        self.L      = float(L)\n\n    @staticmethod\n    def assert_deterministic(model, x, atol=1e-6):\n        \"\"\"Catches accidental randomness when training=False.\"\"\"\n        y1 = model(x[None, ...], training=False)\n        y2 = model(x[None, ...], training=False)\n        tf.debugging.assert_near(y1, y2, atol=atol,\n            message=\"Model appears stochastic at eval; gate all noise with `if training:`.\")\n\n    def certify(self, x, N=100_000, N0=1000, alpha=1e-3, batch=512):\n        # Optional health check (run once per script, not per sample)\n        # self.assert_deterministic(self.model, x)\n\n        r_det    = deterministic_radius(self.model, x, L=self.L)\n        r_smooth = self.smooth.certify(x, N=N, N0=N0, alpha=alpha, batch=batch)\n        return max(r_det, r_smooth), r_det, r_smooth\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Build a clean test dataset like your val pipeline\ndef preprocess(x, y):\n    #return tf.cast(x, tf.float32) / 255.0, y\n    return x, y #tf.cast(x, tf.float32) / 255.0, y\n\ntest_ds = (tf.data.Dataset.from_tensor_slices((X_test_s, y_test_s))\n             .batch(1)\n             .map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n             .prefetch(tf.data.AUTOTUNE))\n\n# HYBRID certification\nfrom hybrid_certifier import HybridCertifier\nSIGMA = 0.5     # MUST equal the sigma you used in GaussianNoise during training\nL     = 1.0     # Set to 1.0 only if every layer is provably ≤1-Lipschitz\n\nhybrid = HybridCertifier(model, sigma=SIGMA, L=L)\n\nclean_ok = det_ok = smooth_ok = hybrid_ok = 0\nN0, N, alpha = 1_000, 100_000, 1e-3\n\nfor x, y in test_ds:\n    true = int(tf.argmax(y, -1).numpy()[0])\n    pred = int(tf.argmax(model(x, training=False), -1).numpy()[0])\n    clean_ok += int(pred == true)\n\n    r_best, r_det, r_smooth = hybrid.certify(tf.squeeze(x, 0), N=N, N0=N0, alpha=alpha, batch=256)\n    det_ok    += int((r_det    > 0) and (pred == true))\n    smooth_ok += int((r_smooth > 0) and (pred == true))\n    hybrid_ok += int((r_best   > 0) and (pred == true))\n\nn_test = len(X_test_s)\nprint(f\"\\nClean acc              : {clean_ok/n_test:.3%}\")\nprint(f\"Deterministic cert acc : {det_ok  /n_test:.3%}\")\nprint(f\"Smoothing    cert acc  : {smooth_ok/n_test:.3%}\")\nprint(f\"HYBRID       cert acc  : {hybrid_ok/n_test:.3%}  (α={alpha}, σ={SIGMA})\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# hybrid_certify.py\nimport tensorflow as tf, numpy as np, math\nfrom pathlib import Path\nfrom scipy.stats import beta, norm    # pip install scipy\n\n# ----------------------------------------------------------------------\n# 0.  Hyper-parameters\n# ----------------------------------------------------------------------\nSIGMA      = 0.5          # std-dev for input Gaussian noise  (train + certify)\nLIPSCHITZ  = 1.0          # global Lipschitz constant of your network\nEPOCHS     = 50\nBATCH_TRAIN= 128\nN0, N      = 1_000, 100_000   # Monte-Carlo sample counts (CIFAR-10 defaults)\nALPHA      = 1e-3             # failure prob → 99.9 % confidence\nCKPT_FILE  = \"hybrid_noise.keras\"\n\n# ----------------------------------------------------------------------\n# 1.  Data  (CIFAR-10 for demo; swap in your own dataset)\n# ----------------------------------------------------------------------\n\n#(x_tr, y_tr), (x_te, y_te) = tf.keras.datasets.cifar10.load_data()\n#C = 10\n#x_tr = x_tr.astype(\"float32\")/255.0; x_te = x_te.astype(\"float32\")/255.0\n#y_tr = tf.keras.utils.to_categorical(y_tr, C); y_te = tf.keras.utils.to_categorical(y_te, C)\n#train_ds = tf.data.Dataset.from_tensor_slices((x_tr, y_tr)).shuffle(50_000).batch(BATCH_TRAIN)\n#test_ds  = tf.data.Dataset.from_tensor_slices((x_te, y_te)).batch(1)  # certify one-by-one\n\n# ----------------------------------------------------------------------\n# 2.  Model  (⇢ put **your own architecture** here)\n# ----------------------------------------------------------------------\n#model      = make_model()\nloss_fn    = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\noptimizer  = tf.keras.optimizers.Adam(1e-3)\nnoise_layer= tf.keras.layers.GaussianNoise(SIGMA)      # input noise\n\n# ----------------------------------------------------------------------\n# 3.  Training loop (Gaussian-noise augmentation every batch)\n# ----------------------------------------------------------------------\n@tf.function(jit_compile=True)\ndef train_step(x, y):\n    with tf.GradientTape() as tape:\n        x_noisy = noise_layer(x, training=True)\n        logits  = model(x_noisy, training=True)\n        loss    = loss_fn(y, logits)\n    grads = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n    acc = tf.reduce_mean(tf.cast(tf.argmax(logits,-1)==tf.argmax(y,-1), tf.float32))\n    return loss, acc\n\nfor epoch in range(1, EPOCHS+1):\n    tot_l, tot_a, n = 0., 0., 0\n    for xb, yb in train_ds:\n        l,a = train_step(xb, yb)\n        bs  = xb.shape[0]\n        tot_l += l.numpy()*bs; tot_a += a.numpy()*bs; n += bs\n    print(f\"Epoch {epoch:02d}: loss={tot_l/n:.4f}  noise-train acc={tot_a/n:.3%}\")\n\nmodel.save(CKPT_FILE)\nprint(\"✓ trained weights saved to\", CKPT_FILE)\n\n# ----------------------------------------------------------------------\n# 4.  Certification utilities\n# ----------------------------------------------------------------------\ndef clopper_low(k, n, alpha): return beta.ppf(alpha/2, k, n-k+1) if k>0 else 0.\ndef clopper_up (k, n, alpha): return beta.ppf(1-alpha/2, k+1, n-k) if k<n else 1.\n\n@tf.function(jit_compile=True)\ndef predict_noisy_batch(x_batch, sigma):\n    noise  = tf.random.normal(tf.shape(x_batch))*sigma\n    logits = model(x_batch+noise, training=False)\n    return tf.argmax(logits, axis=-1)          # int32\n\ndef smoothed_radius(x, sigma=SIGMA, N=N, N0=N0, alpha=ALPHA, batch=512):\n    # Step-1: majority class\n    counts = np.zeros(C, dtype=np.int32)\n    reps   = tf.repeat(x[None,...], batch, axis=0)\n    for done in range(0, N0, batch):\n        m = min(batch, N0-done)\n        preds = predict_noisy_batch(reps[:m], sigma)\n        counts += np.bincount(preds.numpy(), minlength=C)\n    A = counts.argmax()\n\n    # Step-2: estimate p_A\n    k_A = 0\n    for done in range(0, N, batch):\n        m = min(batch, N-done)\n        preds = predict_noisy_batch(reps[:m], sigma)\n        k_A += int(np.sum(preds.numpy()==A))\n    pA_low = clopper_low(k_A, N, alpha)\n    pB_up  = clopper_up (N-k_A, N, alpha)\n    if pA_low<=pB_up:                   # certificate fails\n        return 0.0\n    return sigma * norm.ppf(pA_low)\n\ndef deterministic_radius(x, L=LIPSCHITZ):\n    logits = model(x[None,...], training=False)\n    top2   = tf.nn.top_k(logits, k=2).values\n    margin = (top2[:,0]-top2[:,1])[0].numpy()   # scalar\n    return margin/(2.0*L)\n\ndef hybrid_radius(x):\n    r_det   = deterministic_radius(x)\n    r_smooth= smoothed_radius(x)\n    return max(r_det, r_smooth), r_det, r_smooth\n\n# ----------------------------------------------------------------------\n# 5.  Evaluate clean, deterministic, smoothing, and hybrid accuracies\n# ----------------------------------------------------------------------\nclean_ok, det_ok, smooth_ok, hybrid_ok = 0,0,0,0\n\nfor (x,y) in test_ds:\n    true  = tf.argmax(y, -1).numpy()[0]\n    pred  = tf.argmax(model(x, training=False), -1).numpy()[0]\n    clean_ok += int(pred==true)\n\n    r_h, r_d, r_s = hybrid_radius(tf.squeeze(x,0))\n    det_ok    += int((r_d>0)    and (pred==true))\n    smooth_ok += int((r_s>0)    and (pred==true))\n    hybrid_ok += int((r_h>0)    and (pred==true))\n\nN_TEST = len(x_te)\nprint(\"\\n=== RESULTS (α = {:.0e}, σ = {:.2f}) ===\".format(ALPHA,SIGMA))\nprint(f\"Clean accuracy        : {clean_ok / N_TEST:.3%}\")\nprint(f\"Deterministic cert -r : {det_ok   / N_TEST:.3%}\")\nprint(f\"Smoothing    cert -r : {smooth_ok/ N_TEST:.3%}\")\nprint(f\"HYBRID       cert -r : {hybrid_ok/ N_TEST:.3%}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\nfrom cleverhans.tf2.attacks.projected_gradient_descent import projected_gradient_descent\n\n# 1) Make sure inputs are float32 in [0,1]\ndef to_float01(x):\n    x = tf.convert_to_tensor(x)\n    if x.dtype.is_integer:\n        x = tf.cast(x, tf.float32) / 255.0\n    else:\n        x = tf.cast(x, tf.float32)\n    return x\n\nX_test_f = to_float01(X_test_s)\ny_test_f = y_test_s\n# 2) Labels as int (not one-hot) for metrics; keep one-hot separately if you want AUC-OVR\n'''if 'y_test_one_hot' in globals():\n    y_test_labels = np.argmax(y_test_one_hot, axis=1) if y_test_one_hot.ndim > 1 else np.asarray(y_test_one_hot).astype(int)\nelse:\n    y_test_labels = np.asarray(y_test_s).astype(int)\n'''\nbatch_size = 64\nnum_samples = len(X_test_f)\nnum_batches = (num_samples + batch_size - 1) // batch_size\n\nepsilon_values = [0.016, 0.0313, 0.047, 0.0627]  # feel free to add more\nresults_per_epsilon = []\n\nfor epsilon in epsilon_values:\n    adv_batches = []\n\n    for i in range(num_batches):\n        s = i * batch_size\n        e = min((i + 1) * batch_size, num_samples)\n\n        x_b = X_test_f[s:e]\n        y_b = np.argmax(y_test_f[s:e], axis=1).astype(\"int32\") #y_test_labels[s:e]\n\n        # CleverHans expects tf.Tensors, float32, 0..1; set clip_min/max\n        adv_b = projected_gradient_descent(\n            model_fn=model,\n            x=x_b,\n            eps=tf.cast(epsilon, tf.float32),\n            eps_iter=tf.cast(epsilon/4.0, tf.float32),\n            nb_iter=10,                        # use >1 step for PGD (e.g., 40)\n            norm=np.inf,\n            loss_fn=None,\n            clip_min=0.0,\n            clip_max=1.0,\n            y=tf.convert_to_tensor(y_b, dtype=tf.int32),\n            targeted=False,\n            rand_init=True,                    # typical PGD with random start\n            rand_minmax=epsilon,\n            sanity_checks=False,\n        )\n        adv_batches.append(adv_b.numpy())\n\n    X_adv = np.concatenate(adv_batches, axis=0)\n\n    # 3) Predict on adversarial set\n    logits = model.predict(X_adv, batch_size=128, verbose=0)\n\n    # 4) Handle binary vs multiclass automatically\n    y_pred = tf.squeeze(logits)\n    y_pred_binary = y_pred >= 0.5\n    y_pred_binary = np.array(y_pred_binary, dtype='int32')\n\n    # Calculate evaluation metrics for the current epsilon\n    accuracy = accuracy_score(y_pred_binary, y_test_f) * 100\n    precision = precision_score(y_pred_binary, y_test_f, average='macro') * 100\n    recall = recall_score(y_pred_binary, y_test_f, average='macro') * 100\n    f1 = f1_score(y_pred_binary, y_test_f, average='macro') * 100\n    #auc = roc_auc_score(y_pred, y_test_one_hot) * 100\n\n    # Store results for the current epsilon\n    results_per_epsilon.append({\n        'epsilon': epsilon,\n        'accuracy': accuracy,\n        'precision': precision,\n        'recall': recall,\n        'f1': f1,\n        #'auc': auc\n    })\n\n# Print or use the results as needed\nfor result in results_per_epsilon:\n    print(f\"Epsilon: {result['epsilon']}\")\n    print(f\"Accuracy: {result['accuracy']}\")\n    print(f\"Precision: {result['precision']}\")\n    print(f\"Recall: {result['recall']}\")\n    print(f\"F1 Score: {result['f1']}\")\n    #print(f\"AUC Score: {result['auc']}\")\n    print('-' * 50)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = tf.squeeze(logits)\ny_pred_binary = y_pred >= 0.5\ny_pred_binary = np.array(y_pred_binary, dtype='int32')\n\n# Calculate evaluation metrics for the current epsilon\naccuracy = accuracy_score(y_pred_binary, y_test_f) * 100\nprecision = precision_score(y_pred_binary, y_test_f, average='macro') * 100\nrecall = recall_score(y_pred_binary, y_test_f, average='macro') * 100\nf1 = f1_score(y_pred_binary, y_test_f, average='macro') * 100\n#auc = roc_auc_score(y_pred, y_test_one_hot) * 100\n\n# Store results for the current epsilon\nresults_per_epsilon.append({\n    'epsilon': epsilon,\n    'accuracy': accuracy,\n    'precision': precision,\n    'recall': recall,\n    'f1': f1,\n    #'auc': auc\n})\n\n# Print or use the results as needed\nfor result in results_per_epsilon:\n    print(f\"Epsilon: {result['epsilon']}\")\n    print(f\"Accuracy: {result['accuracy']}\")\n    print(f\"Precision: {result['precision']}\")\n    print(f\"Recall: {result['recall']}\")\n    print(f\"F1 Score: {result['f1']}\")\n    #print(f\"AUC Score: {result['auc']}\")\n    print('-' * 50)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = tf.squeeze(logits)\ny_pred_binary = y_pred >= 0.5\ny_pred_binary = np.array(y_pred_binary, dtype='int32')\n\n# Calculate evaluation metrics for the current epsilon\naccuracy = accuracy_score(y_pred_binary, y_test_f) * 100\nprecision = precision_score(y_pred_binary, y_test_f, average='macro') * 100\nrecall = recall_score(y_pred_binary, y_test_f, average='macro') * 100\nf1 = f1_score(y_pred_binary, y_test_f, average='macro') * 100\n#auc = roc_auc_score(y_pred, y_test_one_hot) * 100\n\n# Store results for the current epsilon\nresults_per_epsilon.append({\n    'epsilon': epsilon,\n    'accuracy': accuracy,\n    'precision': precision,\n    'recall': recall,\n    'f1': f1,\n    #'auc': auc\n})\n\n# Print or use the results as needed\nfor result in results_per_epsilon:\n    print(f\"Epsilon: {result['epsilon']}\")\n    print(f\"Accuracy: {result['accuracy']}\")\n    print(f\"Precision: {result['precision']}\")\n    print(f\"Recall: {result['recall']}\")\n    print(f\"F1 Score: {result['f1']}\")\n    #print(f\"AUC Score: {result['auc']}\")\n    print('-' * 50)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}